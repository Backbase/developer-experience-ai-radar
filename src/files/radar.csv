name,ring,quadrant,isNew,description
Continuous delivery for machine learning (CD4ML),Trial,Dev Ops,FALSE,"<p>About a decade ago we introduced <a href=""/radar/Techniques/continuous-delivery-cd"">continuous delivery (CD)</a>, our default way to deliver software solutions. Today's solutions increasingly include machine-learning models and we find them no exception in adopting continuous delivery practices. We call this <strong><a href=""https://martinfowler.com/articles/cd4ml.html"">continuous delivery for machine learning (CD4ML)</a></strong>. Although the principles of CD remain the same, the practices and tools to implement the end-to-end process of training, testing, deploying and monitoring models require some modifications. For example: version control must not only include code but also the data, the models and its parameters; the testing pyramid extends to include model bias, fairness and data and feature validation; the deployment process must consider how to promote and evaluate the performance of new models against current champion models. While the industry is celebrating the new buzzword of MLOps, we feel CD4ML is our holistic approach to implement an end-to-end process to reliably release and continuously improve machine-learning models, from idea to production.</p>"
Bounded low-code platforms,Assess,Dev,TRUE,"<p>One of the most nuanced decisions facing companies at the moment is the adoption of low-code or no-code platforms, that is, platforms that solve very specific problems in very limited domains. Many vendors are pushing aggressively into this space. The problems we see with these platforms typically relate to an inability to apply good engineering practices such as versioning. Testing too is typically really hard. However, we noticed some interesting new entrants to the market â€” including <a href=""https://www.honeycode.aws/"">Amazon Honeycode</a>, which makes it easy to create simple task or event management apps, and <a href=""https://parabola.io/"">Parabola</a> for IFTTT-like cloud workflows â€” which is why we're including <strong>bounded low-code platforms</strong> in this volume. Nevertheless, we remain deeply skeptical about their wider applicability since these tools, like Japanese Knotweed, have a knack of escaping their bounds and tangling everything together. That's why we still strongly advise caution in their adoption.</p>"
Productionizing notebooks,Hold,Dev,FALSE,"<p>Over the last few decades <a href=""https://en.wikipedia.org/wiki/Notebook_interface"">computational notebooks</a>, first introduced by <a href=""https://en.wikipedia.org/wiki/Wolfram_Mathematica"">Wolfram Mathematica</a>, have evolved to support scientific research, exploration and educational workflows. Naturally, in support of data science workflows and with the likes of <a href=""https://jupyter.org/"">Jupyter notebooks</a> and <a href=""https://docs.databricks.com/notebooks/index.html"">Databricks notebooks</a>, they've become a great companion by providing a simple and intuitive interactive computation environment for combining code to analyze data with rich text and visualization to tell a data story. Notebooks were designed to provide an ultimate medium for modern scientific communication and innovation. In recent years, however, we've seen a trend for notebooks to be the medium for running the type of production-quality code typically used to drive enterprise operations. We see notebook <a href=""https://databricks.com/blog/2017/10/30/continuous-integration-continuous-delivery-databricks.html"">platform providers advertising</a> the use of their exploratory notebooks in production. This is a case of good intentions â€” democratizing programming for data scientists â€” implemented poorly and at the cost of scalability, maintainability, resiliency and all the other qualities that a long-lived production code needs to support. We don't recommend <strong>productionizing notebooks</strong> and instead encourage empowering data scientists to build production-ready code with the right programming frameworks, thus simplifying the <a href=""/radar/Techniques/continuous-delivery-for-machine-learning-cd4ml"">continuous delivery</a> tooling and abstracting complexity away through end-to-end ML platforms.</p>"
Screen testing,Trial,QA,TRUE,"<div><p>Context</p><p>Currently our visual testing is high effort with lot of manual steps, we currently manually verify changes and have no standard process keep Figma is sync.As such we have many quality issues in MAINTs, over XXX found by GDT alone this year. Customers also find many discrepancies between what is shown in Figma and what is seen in Code.</p><p>Previously automation tooling has been analysed by typical QA vendors, but has been cost prohibitive.</p><p>Plan & unlocked value</p><p>We have shown in a POC ðŸ”— it is possible to leverage the new version of ChatGPT-o to compare two images (Version A vs version B or Figma vs Code) at a fraction of the cost. Annual costs:
Apitools reported to be appx $100,000 to $200,000 per year</p><p>ChatGPT method = $0.5 per 100 images = $5,000 per year for 100,000 images</p>
<p>This can be automated via APIs and issues reported in tickets clearly to anyone in an understandable way.  This will also reduce the efforts in QA triage and ticket created that could account for XXX days per year.</p><p>Insights</p><p>GDT Global Branding MAINTS Dashboard</p><p>123 Global Branding Issues found</p><p>Theming testing on TVP for the first time in R&D</p></div>
"
