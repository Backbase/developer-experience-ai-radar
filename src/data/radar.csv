name,ring,quadrant,isNew,description
AI QA Vision,Trial,tools,TRUE,"<p>Currently our visual testing is high effort with lot of manual steps, we currently manually verify changes and have no standard process keep Figma is sync. As such we have many quality issues in MAINTs, over XXX found by GDT alone this year. Customers also find many discrepancies between what is shown in Figma and what is seen in Code. Previously automation tooling has been analysed by typical QA vendors, but has been cost prohibitive.</p><p>Plan & unlocked value</p><p>We have shown in a POC ðŸ”— it is possible to leverage the new version of ChatGPT-o to compare two images (Version A vs version B or Figma vs Code) at a fraction of the cost. Annual costs:</p><p>Apitools reported to be appx $100,000 to $200,000 per year</p><p>ChatGPT method = $0.5 per 100 images = $5,000 per year for 100,000 images</p><p>This can be automated via APIs and issues reported in tickets clearly to anyone in an understandable way.  This will also reduce the efforts in QA triage and ticket created that could account for XXX days per year.</p><p>Contact: Craig Walker / Roman Lovlev</p>"
AI Mock Data Generation,Assess,tools,TRUE,"<p>Our current data for demos, testing, and onboarding is limited in regional coverage, making it suitable only for specific regions and failing to address diverse regional needs effectively.</p><p>This initiative explores how LLM tools can help generate region-specific Synthetic data to create localized demo and initial deployment experiences, and tailoring excellence through customization of test data, edge case testing simulation, and improve overall product sell-ability.</p><p>For QA, generating datasets to more extensive and varied use cases the are more accurate to the various cases that appear across the world. e.g. In Norway itâ€™s common to have 50-100 accounts but in UK they might have 4-8 Accounts.</p><p>For Showcase, ability to generate regional specific dome that contain localised transactions and data more applicable to enhance the demo for the customer. e.g. Generating more high net worth users and scenarios</p><p>Contact: Rami Heikel / Olena Chubukine</p>"
AI Pull request analysis,Assess,tools,TRUE,<p>AI tools part of the SDLC for: </p><p><ol><li>Continuous Merges: automatic approval of PRs based on a categorisation</li><li>Breaking changes detection</li><li>Assigning code reviewers based on the scope</li><li>API docs generation</li><li>PR summary</li></ol></p><Contacts: Ilya Mikhailov / Jose Cortes</p>
AI Slack Bot Assistant,Assess,tools,TRUE,"<p>To develop a Slackbot that integrates with an existing solution and connects to the API: https://oai.stg.azure.backbase.eu, facilitating automated, accurate responses to common queries. Reduce effort for R&D spent on support in slack through automated FAQ gathering and responces.</p><p>Contact: Aleksandr Nagaikin / Craig Walker</p>"
AI Api Doc Generation,Assess,tools,TRUE,"<p>Our current API reference documentation lacks completeness and consistency. Missing descriptions of functions, configuration options, attributes, and properties, combined with inconsistencies across different journeys, apps, and technologies, make the references less valuable to developers. Whether users are accessing the documentation from Backbase.io or within their IDE, the lack of clarity and structure hinders their productivity.</p><p>Plan & unlocked value</p><p>Rank the quality of our API references for prioritization, research a tool that can help us generate great reference information without the input of engineers and hook the tool into our CI/CD so it can output content for Backbase.io.</p><p>Enable documentation in the IDE (each stack would have a different way)</p><p>Improved Developer Experience: By providing clear, consistent documentation directly accessible through their IDE or via Backbase.io, we aim to reduce the time engineers spend searching and troubleshooting. Currently, 40% of engineers spend 10-20 hours a week working with API related tasks, a good experience is key to make that time meaningful.</p><p>Discoverability: We enhance discoverability by integrating our API documentation directly into IDEs and offering a robust search feature on Backbase.io. This ensures developers can effortlessly access and implement APIs, minimizing time spent searching for the right information.</p><p>Contact: Rami Hiekel / Igor Dimitrijevic</p>"
AI QA Page Object Generation,Assess,tools,TRUE,<p>Automate Page Objects creation process. Adopt standard Backbase approach for Page Objects. Regenerate and correct Page Objects for changed locators. This would look a bit like:</p><p>Open Html page of working feature and generate Page object for it based on HTML. See Github: qa-ai-page-objects-generator</p><p>Generate Page Objects based on Requirements and Figma Designs (before feature development)</p><p>Side effect: Follow Golden Sample and Backbase Best Practices</p>
AI Assisted Accessibility testing,Assess,tools,TRUE,"<p>For UX, QA, Devs - Look at how some of the criterion that arenâ€™t covered bye axe library to speed up some of the checks we need to carry out and make them a regular part of our process instead of carrying out large scale audits. (@Edward Rothwell  for clarification).</p><p>Examples/Problems to solve:</p><p><ul><li>Pixel measurement - Understanding Success Criterion 2.5.8: Target Size (Minimum) | WAI | W3C . Currently no reliable method for measure pixels. </li><li>Consistent help - Understanding Success Criterion 3.2.6: Consistent Help | WAI | W3C . If we have help in our apps, being able to automate this would be really nice.</li><li>Checking all items in an app that should be focusable are focusable (visual test would require multiple snapshots, Iâ€™m thinking we could probably do something a lot smarter, but would need to brainstorm).</li><li>Resize text/text spacing/page zooming. </li><li>Error identification</li></ul></p>"